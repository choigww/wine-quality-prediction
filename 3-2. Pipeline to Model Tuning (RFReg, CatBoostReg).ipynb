{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "continued-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn import svm\n",
    "# from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from scipy.stats import randint\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from time import time\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-command",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "derived-cooper",
   "metadata": {},
   "source": [
    "# Model Tuning: Preprocess to Hyperparameter Tuning\n",
    "CatBoost Regressor & RandomForest Regressor\n",
    "\n",
    "<br>\n",
    "\n",
    "## CatBoost Regressor\n",
    "\n",
    "<br>\n",
    "\n",
    "### Result\n",
    "- Best Cross Validation (StratifiedKFold, n_splits=5) MSE\n",
    "    - 0.395\n",
    "- Test MSE\n",
    "    - 0.423\n",
    "\n",
    "<br>\n",
    "\n",
    "### Setting\n",
    "- Local Outlier Factor\n",
    "    - `n_neighbors` = 30\n",
    "    - applied to non-stratified train set (MinMaxScaler)  \n",
    "- Pipeline\n",
    "\n",
    "```python\n",
    "# train set scaler = MinMaxScaler()\n",
    "OrderedDict([('bagging_temperature', 0.0),\n",
    "             ('border_count', 112),\n",
    "             ('depth', 8),\n",
    "             ('iterations', 918),\n",
    "             ('l2_leaf_reg', 26),\n",
    "             ('learning_rate', 0.03284111014718372),\n",
    "             ('random_strength', 6.959012504143357e-06)])\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Model Performance in Detail\n",
    "- accuracy (반올림한 예측값과 실제 타깃이 같은 비율)\n",
    "    - 0.567\n",
    "- mse_by_target = 각 실제 타깃별로 계산한 MSE\n",
    "\n",
    "target|accuracy|mse_by_target\n",
    "-|-|-\n",
    "3|0.000000|3.901136\n",
    "4|0.000000|2.166643\n",
    "5|0.680851|0.237111\n",
    "6|0.608333|0.252474\n",
    "7|0.333333|0.725133\n",
    "8|0.000000|2.394219\n",
    "\n",
    "<br>\n",
    "\n",
    "## RandomForest Regressor\n",
    "\n",
    "<br>\n",
    "\n",
    "### Result\n",
    "- Best Cross Validation (StratifiedKFold, n_splits=5) MSE\n",
    "    - 0.396\n",
    "- Test MSE\n",
    "    - 0.484\n",
    "\n",
    "<br>\n",
    "\n",
    "### Setting\n",
    "- Local Outlier Factor\n",
    "    - `n_neighbors` = 23\n",
    "    - applied to stratified train set (StandardScaler)  \n",
    "- Pipeline\n",
    "\n",
    "```python\n",
    "# train set scaler = RobustScaler()\n",
    "\n",
    "OrderedDict([('bootstrap', True),\n",
    "             ('max_depth', 22),\n",
    "             ('max_features', 'sqrt'),\n",
    "             ('min_samples_leaf', 1),\n",
    "             ('min_samples_split', 2),\n",
    "             ('n_estimators', 1001)])\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Model Performance in Detail\n",
    "- accuracy (반올림한 예측값과 실제 타깃이 같은 비율)\n",
    "    - 0.569\n",
    "- mse_by_target = 각 실제 타깃별로 계산한 MSE\n",
    "\n",
    "\n",
    "target|accuracy|mse_by_target\n",
    "-|-|-\n",
    "3|0.000000|3.817969\n",
    "4|0.000000|2.082316\n",
    "5|0.794643|0.216085\n",
    "6|0.504854|0.328223\n",
    "7|0.250000|0.960480\n",
    "8|0.000000|3.210739\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-phone",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fifty-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.8              0.88         0.00             2.6      0.098   \n",
       "1            7.8              0.76         0.04             2.3      0.092   \n",
       "2           11.2              0.28         0.56             1.9      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "1                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "2                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.8        5  \n",
       "1      9.8        5  \n",
       "2      9.8        6  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "red = pd.read_csv('./data/winequality-red.csv', sep=';')\n",
    "red = red.drop_duplicates(keep='last', ignore_index=True)\n",
    "red.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "powered-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2021\n",
    "\n",
    "def split_data(df, seed, stratify=True):\n",
    "        X = df.drop('quality',axis=1)\n",
    "        y = df['quality']\n",
    "        if stratify:\n",
    "            return train_test_split(X, y,\n",
    "                                    test_size=0.2,\n",
    "                                    stratify=y,\n",
    "                                    shuffle=True,\n",
    "                                    random_state=seed)\n",
    "        else:\n",
    "            return train_test_split(X, y,\n",
    "                                    test_size=0.2,\n",
    "                                    shuffle=True,\n",
    "                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lined-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(red, seed=RANDOM_SEED, stratify=False)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_data(red, seed=RANDOM_SEED, stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-april",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "piano-regular",
   "metadata": {},
   "source": [
    "# Tuning CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "amateur-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_grid_search_with_pipeline(Xtr, Xte, ytr, yte, pipe, params, iter_num, seed,\n",
    "                                     is_not_mute=1, stratify=True):\n",
    "    if stratify:\n",
    "        r_grid = RandomizedSearchCV(pipe, params,\n",
    "                             scoring = 'neg_mean_squared_error',\n",
    "                             cv=StratifiedKFold(n_splits=5,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=seed),\n",
    "                             verbose=is_not_mute, n_jobs=-1, n_iter=iter_num, random_state=seed)\n",
    "    else:\n",
    "        r_grid = RandomizedSearchCV(pipe, params,\n",
    "                             scoring = 'neg_mean_squared_error',\n",
    "                             cv=KFold(n_splits=5,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=seed),\n",
    "                             verbose=is_not_mute, n_jobs=-1, n_iter=iter_num, random_state=seed)\n",
    "    \n",
    "    r_grid.fit(Xtr, ytr)\n",
    "    if is_not_mute:\n",
    "        print(r_grid.best_params_)\n",
    "        print('Best CV MSE', -1 * r_grid.best_score_)\n",
    "        print('Test MSE', np.mean(np.square(r_grid.predict(Xte) - yte)))\n",
    "    return r_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "sitting-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF tuning\n",
    "def LOF_tuning(df, param_dict, pipe, pipe_param_dict, stratify = True, seed=RANDOM_SEED):\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = split_data(df, seed=seed, stratify=stratify)\n",
    "    \n",
    "    # normalize data\n",
    "    X_scaler = param_dict['scaler']\n",
    "    X_train_std = X_scaler.fit_transform(Xtrain)\n",
    "    X_test_std = X_scaler.transform(Xtest)\n",
    "    \n",
    "    best_cv_score = 100\n",
    "    best_n_neighbors = 0\n",
    "    best_grid = ''\n",
    "    best_dataset = []\n",
    "    \n",
    "    # outlier removal using Local Outlier Factor\n",
    "    n_neighbors_list = param_dict['n_neighbors']\n",
    "    for i, nn in enumerate(n_neighbors_list):\n",
    "        lof = LocalOutlierFactor(n_neighbors=nn)\n",
    "        y_pred_std = lof.fit_predict(X_train_std)\n",
    "        outlier_idx = np.where(y_pred_std==-1)[0]\n",
    "        \n",
    "        X_train_lof, X_test_lof, y_train_lof, y_test_lof = split_data(df.drop(outlier_idx),\n",
    "                                                                     seed=seed,\n",
    "                                                                     stratify=stratify)        \n",
    "        rand_grid = random_grid_search_with_pipeline(X_train_lof,\n",
    "                                                     X_test_lof,\n",
    "                                                     y_train_lof,\n",
    "                                                     y_test_lof,\n",
    "                                                     pipe,\n",
    "                                                     pipe_param_dict,\n",
    "                                                     iter_num=1000,\n",
    "                                                     seed=seed,\n",
    "                                                     is_not_mute=0,\n",
    "                                                     stratify=stratify)\n",
    "    \n",
    "        if (-1 * rand_grid.best_score_) < best_cv_score:\n",
    "            best_cv_score = -1 * rand_grid.best_score_\n",
    "            best_grid = rand_grid\n",
    "            best_n_neighbors = nn\n",
    "            best_dataset = X_train_lof, X_test_lof, y_train_lof, y_test_lof\n",
    "            print(f'update: {best_cv_score}')\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('/', end=' ')\n",
    "        \n",
    "    return best_dataset, best_n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "artistic-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_base = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', CatBoostRegressor())\n",
    "                ])\n",
    "\n",
    "param_base = [              \n",
    "              {'regressor': [CatBoostRegressor()],\n",
    "               'regressor__loss_function' : ['RMSE'],\n",
    "               'regressor__silent':[True],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "              }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "authentic-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.43274947723274126\n",
      "/ update: 0.4224019349333469\n",
      "update: 0.4134534329460271\n",
      "/ update: 0.40446484347330935\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_mms = {'scaler':MinMaxScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_mms, best_neighbor_param_mms = LOF_tuning(red, lof_param_mms,\n",
    "                                                        pipe_base, param_base,\n",
    "                                                        stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-application",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laden-vancouver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4336457575825608\n",
      "/ update: 0.42900641837758685\n",
      "update: 0.42631952771922715\n",
      "update: 0.4168671702102279\n",
      "update: 0.41003106528933053\n",
      "/ update: 0.40497030084265234\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_ss = {'scaler':StandardScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_ss, best_neighbor_param_ss = LOF_tuning(red, lof_param_ss,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-somerset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "featured-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4410327844659901\n",
      "/ update: 0.4389211206853398\n",
      "update: 0.4350800275736895\n",
      "update: 0.4183417887438073\n",
      "update: 0.4182084541760701\n",
      "/ update: 0.41093235501256214\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_rs = {'scaler':RobustScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_rs, best_neighbor_param_rs = LOF_tuning(red, lof_param_rs,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "exceptional-musical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# best n_neighbors = 30\n",
    "print(best_neighbor_param_mms)\n",
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = best_lof_data_mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-litigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "flush-discretion",
   "metadata": {},
   "source": [
    "### Pipeline & Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "monetary-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': MinMaxScaler(copy=True, feature_range=(0, 1)), 'regressor__silent': True, 'regressor__random_state': 2021, 'regressor__loss_function': 'RMSE', 'regressor': <catboost.core.CatBoostRegressor object at 0x1a22448090>}\n",
      "Best CV MSE 0.45694873485709797\n",
      "Test MSE 0.37965734832707604\n"
     ]
    }
   ],
   "source": [
    "# original data (no LOF)\n",
    "# scaler opt only\n",
    "pipe_no_prep_opt = Pipeline([\n",
    "                ('scale', RobustScaler()),\n",
    "                ('regressor', CatBoostRegressor())\n",
    "                ])\n",
    "\n",
    "param_no_prep_opt = [              \n",
    "              {'regressor': [CatBoostRegressor()],\n",
    "               'regressor__silent':[True],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'regressor__loss_function' : ['RMSE'],\n",
    "               'scale':[RobustScaler(), StandardScaler(), MinMaxScaler()],\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd_no_prep_opt0 = random_grid_search_with_pipeline(X_train, X_test, y_train, y_test,\n",
    "                                pipe_no_prep_opt, param_no_prep_opt, iter_num=100,\n",
    "                                                     seed=RANDOM_SEED,\n",
    "                                                    stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cooperative-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': StandardScaler(copy=True, with_mean=True, with_std=True), 'regressor__silent': True, 'regressor__random_state': 2021, 'regressor__loss_function': 'RMSE', 'regressor': <catboost.core.CatBoostRegressor object at 0x1a21a7f510>}\n",
      "Best CV MSE 0.40446484347330935\n",
      "Test MSE 0.4400908780717685\n"
     ]
    }
   ],
   "source": [
    "# scaler opt only\n",
    "pipe_no_prep_opt = Pipeline([\n",
    "                ('scale', RobustScaler()),\n",
    "                ('regressor', CatBoostRegressor())\n",
    "                ])\n",
    "\n",
    "param_no_prep_opt = [              \n",
    "              {'regressor': [CatBoostRegressor()],\n",
    "               'regressor__silent':[True],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'regressor__loss_function' : ['RMSE'],\n",
    "               'scale':[RobustScaler(), StandardScaler(), MinMaxScaler()],\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd_no_prep_opt = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe_no_prep_opt, param_no_prep_opt, iter_num=100,\n",
    "                                                     seed=RANDOM_SEED,\n",
    "                                                    stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sticky-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'CatBoost Feature Importance')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "X_train_lof_mms = mms.fit_transform(X_train_lof)\n",
    "X_test_lof_mms = mms.transform(X_test_lof)\n",
    "\n",
    "cbr = CatBoostRegressor(silent=True, random_state=RANDOM_SEED, loss_function='RMSE')\n",
    "cbr.fit(X_train_lof_mms, y_train_lof)\n",
    "\n",
    "sorted_feature_importance = cbr.feature_importances_.argsort()\n",
    "plt.barh(red.drop('quality', axis=1).columns[sorted_feature_importance], \n",
    "        cbr.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel(\"CatBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-leonard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minute-payday",
   "metadata": {},
   "source": [
    "### BayesianSearchCV -> 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "realistic-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting util for different optimizers\n",
    "def report_perf(optimizer, X, y, title, callbacks=None):\n",
    "    start = time()\n",
    "    if callbacks:\n",
    "        optimizer.fit(X, y, callback=callbacks)\n",
    "    else:\n",
    "        optimizer.fit(X, y)\n",
    "    d=pd.DataFrame(optimizer.cv_results_)\n",
    "    best_score = optimizer.best_score_\n",
    "    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n",
    "    best_params = optimizer.best_params_\n",
    "    \n",
    "    try:\n",
    "        print((title + \" - candidates checked: %d, best CV score: %.3f \"\n",
    "               +u\"\\u00B1\"+\" %.3f\") % (len(optimizer.cv_results_['params']),\n",
    "                                      best_score,\n",
    "                                      best_score_std))    \n",
    "        print('Best parameters:')\n",
    "        pprint.pprint(best_params)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return optimizer, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "comparative-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = CatBoostRegressor(silent=True,\n",
    "                       loss_function='RMSE',\n",
    "                       random_state=RANDOM_SEED)\n",
    "\n",
    "param_catboost = [              \n",
    "              {'iterations': Integer(10, 1000),\n",
    "               'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "               'random_strength': Real(1e-9, 10, 'log-uniform'),\n",
    "               'bagging_temperature': Real(0.0, 1.0),\n",
    "               'border_count': Integer(1, 255),\n",
    "               'depth' : Integer(2, 10),\n",
    "               'l2_leaf_reg' : Integer(2, 30)\n",
    "               }\n",
    "             ]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "labeled-telling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Searching for the next optimal point.\n",
      "Iteration No: 1 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1777\n",
      "Function value obtained: 0.4910\n",
      "Current minimum: 0.4910\n",
      "Iteration No: 2 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 2 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3500\n",
      "Function value obtained: 0.5866\n",
      "Current minimum: 0.4910\n",
      "Iteration No: 3 started. Searching for the next optimal point.\n",
      "Iteration No: 3 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.6414\n",
      "Function value obtained: 0.3977\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 4 started. Searching for the next optimal point.\n",
      "Iteration No: 4 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8341\n",
      "Function value obtained: 0.4246\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 5 started. Searching for the next optimal point.\n",
      "Iteration No: 5 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5725\n",
      "Function value obtained: 0.4913\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1175\n",
      "Function value obtained: 0.4380\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8127\n",
      "Function value obtained: 0.6164\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.2111\n",
      "Function value obtained: 0.4079\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4178\n",
      "Function value obtained: 0.4028\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9203\n",
      "Function value obtained: 0.5648\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8076\n",
      "Function value obtained: 0.3995\n",
      "Current minimum: 0.3977\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.5179\n",
      "Function value obtained: 0.3954\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.9327\n",
      "Function value obtained: 0.4153\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.7362\n",
      "Function value obtained: 0.4350\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.7956\n",
      "Function value obtained: 0.4147\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.6593\n",
      "Function value obtained: 0.4004\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 55.1357\n",
      "Function value obtained: 0.3963\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.8480\n",
      "Function value obtained: 0.4146\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 57.3724\n",
      "Function value obtained: 0.4043\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3225\n",
      "Function value obtained: 0.4081\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 31.1770\n",
      "Function value obtained: 0.5191\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4566\n",
      "Function value obtained: 0.4456\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.0955\n",
      "Function value obtained: 0.4101\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 44.5962\n",
      "Function value obtained: 0.4042\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.2966\n",
      "Function value obtained: 0.5555\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3781\n",
      "Function value obtained: 0.6557\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.0708\n",
      "Function value obtained: 0.4081\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.8729\n",
      "Function value obtained: 0.4131\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.1507\n",
      "Function value obtained: 0.4023\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5455\n",
      "Function value obtained: 0.4939\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3691\n",
      "Function value obtained: 0.4067\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.4653\n",
      "Function value obtained: 0.4059\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.2995\n",
      "Function value obtained: 0.4086\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.4458\n",
      "Function value obtained: 0.4707\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.7896\n",
      "Function value obtained: 0.4216\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 59.8218\n",
      "Function value obtained: 0.4001\n",
      "Current minimum: 0.3954\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "CatBoost - candidates checked: 36, best CV score: -0.395 ± 0.068\n",
      "Best parameters:\n",
      "OrderedDict([('bagging_temperature', 0.0),\n",
      "             ('border_count', 112),\n",
      "             ('depth', 8),\n",
      "             ('iterations', 918),\n",
      "             ('l2_leaf_reg', 26),\n",
      "             ('learning_rate', 0.03284111014718372),\n",
      "             ('random_strength', 6.959012504143357e-06)])\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 100\n",
    "\n",
    "opt = BayesSearchCV(reg,\n",
    "                    param_catboost,\n",
    "                     scoring=mse,\n",
    "                    cv=kf,\n",
    "                    n_iter=N_ITER,\n",
    "                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=RANDOM_SEED,\n",
    "                   verbose=0)\n",
    "\n",
    "optimizer, best_params = report_perf(opt, X_train_lof_mms, y_train_lof, 'CatBoost', \n",
    "                          callbacks=[VerboseCallback(100), \n",
    "                                     DeadlineStopper(60*10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "negative-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39541721912317396"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * optimizer.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "changing-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bagging_temperature', 0.0),\n",
       "             ('border_count', 112),\n",
       "             ('depth', 8),\n",
       "             ('iterations', 918),\n",
       "             ('l2_leaf_reg', 26),\n",
       "             ('learning_rate', 0.03284111014718372),\n",
       "             ('random_strength', 6.959012504143357e-06)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "present-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "best_params_cbr = OrderedDict([('bagging_temperature', 0.0),\n",
    "                             ('border_count', 112),\n",
    "                             ('depth', 8),\n",
    "                             ('iterations', 918),\n",
    "                             ('l2_leaf_reg', 26),\n",
    "                             ('learning_rate', 0.03284111014718372),\n",
    "                             ('random_strength', 6.959012504143357e-06)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "confirmed-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42867967032629933\n"
     ]
    }
   ],
   "source": [
    "best_reg = CatBoostRegressor(**best_params_cbr,\n",
    "                        silent=True,\n",
    "                       loss_function='RMSE',\n",
    "                       random_state=RANDOM_SEED)\n",
    "\n",
    "best_reg.fit(X_train_lof_mms, y_train_lof)\n",
    "best_pred = best_reg.predict(X_test_lof_mms)\n",
    "\n",
    "print(np.mean(np.square(best_pred - y_test_lof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "advisory-essex",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "attempted-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_analysis(y_hat, y):\n",
    "    # 반올림한 예측값을 사용하여 accuracy 계산\n",
    "    acc = np.sum(np.round(y_hat) == np.array(y)) / len(y)\n",
    "    \n",
    "    # 반올림한 예측값과 실제 타깃이 같지 않은 인덱스\n",
    "    pred_false_index = pd.Series(np.round(y_hat) == np.array(y)) == False\n",
    "    \n",
    "    # 모델이 맞추는 데 실패한 타깃의 실제 값\n",
    "    pred_false_target = pd.Series(y).reset_index(drop=True)[pred_false_index]\n",
    "    \n",
    "    # 타깃 값(3,4,...,8) 별 갯수\n",
    "    false_target_vc = pred_false_target.value_counts()\n",
    "    real_target_vc = y.value_counts()\n",
    "    \n",
    "    # 타깃 값 별로 반올림한 예측값이 동일할 확률을 데이터프레임으로 저장\n",
    "    df_acc = pd.DataFrame(1-(false_target_vc / real_target_vc)).rename(columns={'quality':'accuracy'})\n",
    "    \n",
    "    # 각 타깃 값(3,4,...,8) 별로 각각의 MSE를 계산하여 저장\n",
    "    mask_target_by_unq = [(np.array(y)==unq_target) for unq_target in np.unique(y)]\n",
    "    mse_by_target = []\n",
    "    \n",
    "    for idx in df_acc.index.tolist():\n",
    "        mask = mask_target_by_unq[idx-3]\n",
    "        target_masked = np.array(y)[mask]\n",
    "        pred_masked = np.array(y_hat)[mask]\n",
    "        mse = np.mean(np.square(pred_masked - target_masked))\n",
    "        mse_by_target.append(mse)\n",
    "\n",
    "    df_acc['mse_by_target'] = mse_by_target\n",
    "    \n",
    "    return df_acc.sort_index(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "executed-chemistry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5665399239543726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mse_by_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.901136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.166643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.237111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.252474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.725133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.394219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  mse_by_target\n",
       "3  0.000000       3.901136\n",
       "4  0.000000       2.166643\n",
       "5  0.680851       0.237111\n",
       "6  0.608333       0.252474\n",
       "7  0.333333       0.725133\n",
       "8  0.000000       2.394219"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc, acc = result_analysis(best_pred, y_test_lof)\n",
    "\n",
    "print(acc)\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-reducing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "numerous-scotland",
   "metadata": {},
   "source": [
    "# Tuning RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "circular-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_base = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', RandomForestRegressor())\n",
    "                ])\n",
    "\n",
    "param_base = [              \n",
    "              {'regressor': [RandomForestRegressor()],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "              }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "convinced-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4261750442909026\n",
      "/ update: 0.4187871090047393\n",
      "/ update: 0.4111378095238095\n"
     ]
    }
   ],
   "source": [
    "lof_param_mms = {'scaler':MinMaxScaler(),\n",
    "            'n_neighbors':range(10, 30)}\n",
    "best_lof_data_mms, best_neighbor_param_mms = LOF_tuning(red, lof_param_mms,\n",
    "                                                        pipe_base, param_base,\n",
    "                                                       stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reverse-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4450021596244131\n",
      "/ update: 0.4362002480290548\n",
      "update: 0.43228075829383894\n",
      "update: 0.42901701466937486\n",
      "update: 0.4105966666666667\n",
      "/ update: 0.4007713328776486\n"
     ]
    }
   ],
   "source": [
    "lof_param_ss = {'scaler':StandardScaler(),\n",
    "            'n_neighbors':range(10, 30)}\n",
    "best_lof_data_ss, best_neighbor_param_ss = LOF_tuning(red, lof_param_ss,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                     stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "upset-qatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4285350870957834\n",
      "/ / update: 0.41983281856389165\n",
      "update: 0.41827108327691265\n",
      "update: 0.4124112599681021\n"
     ]
    }
   ],
   "source": [
    "lof_param_rs = {'scaler':RobustScaler(),\n",
    "            'n_neighbors':range(10, 30)}\n",
    "best_lof_data_rs, best_neighbor_param_rs = LOF_tuning(red, lof_param_rs,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                     stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cloudy-toronto",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# best n_neighbors = 23\n",
    "print(best_neighbor_param_ss)\n",
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = best_lof_data_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-russian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eligible-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': StandardScaler(copy=True, with_mean=True, with_std=True), 'regressor__random_state': 2021, 'regressor': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=2021, verbose=0, warm_start=False)}\n",
      "Best CV MSE 0.4294188124128017\n",
      "Test MSE 0.37899889705882356\n"
     ]
    }
   ],
   "source": [
    "# original data (no LOF)\n",
    "# scaler opt only\n",
    "pipe_no_prep_opt = Pipeline([\n",
    "                ('scale', RobustScaler()),\n",
    "                ('regressor', RandomForestRegressor())\n",
    "                ])\n",
    "\n",
    "param_no_prep_opt = [              \n",
    "              {'regressor': [RandomForestRegressor()],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'scale':[RobustScaler(), StandardScaler(), MinMaxScaler()],\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd_no_prep_opt0 = random_grid_search_with_pipeline(X_train2, X_test2, y_train2, y_test2,\n",
    "                                pipe_no_prep_opt, param_no_prep_opt, iter_num=100, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adequate-province",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True), 'regressor__random_state': 2021, 'regressor': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=2021, verbose=0, warm_start=False)}\n",
      "Best CV MSE 0.4007713328776486\n",
      "Test MSE 0.4452461832061068\n"
     ]
    }
   ],
   "source": [
    "# scaler opt only\n",
    "pipe_no_prep_opt = Pipeline([\n",
    "                ('scale', RobustScaler()),\n",
    "                ('regressor', RandomForestRegressor())\n",
    "                ])\n",
    "\n",
    "param_no_prep_opt = [              \n",
    "              {'regressor': [RandomForestRegressor()],\n",
    "                'regressor__random_state':[RANDOM_SEED],\n",
    "               'scale':[RobustScaler(), StandardScaler(), MinMaxScaler()],\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd_no_prep_opt = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe_no_prep_opt, param_no_prep_opt, iter_num=100, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-fourth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "rural-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'RandomForest Feature Importance')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_train_lof_rs = rs.fit_transform(X_train_lof)\n",
    "X_test_lof_rs = rs.transform(X_test_lof)\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "rfr.fit(X_train_lof_rs, y_train_lof)\n",
    "\n",
    "sorted_feature_importance = rfr.feature_importances_.argsort()\n",
    "plt.barh(red.drop('quality', axis=1).columns[sorted_feature_importance], \n",
    "        cbr.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel(\"RandomForest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-tribe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acquired-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "param_randomforest = [              \n",
    "              {'n_estimators': Integer(100, 1001),\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': Integer(3, 31),\n",
    "               'min_samples_split': Integer(2, 11),\n",
    "               'min_samples_leaf': Integer(1, 5),\n",
    "               'bootstrap' : [True, False]\n",
    "               }\n",
    "             ]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,\n",
    "                      shuffle=True,\n",
    "                      random_state=RANDOM_SEED)\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "opt = BayesSearchCV(reg,\n",
    "                    param_randomforest,\n",
    "                     scoring=mse,\n",
    "                    cv=skf,\n",
    "                    n_iter=100,\n",
    "                    n_jobs=1,  # use just 1 job with CatBoost in order to avoid segmentation fault\n",
    "                    return_train_score=False,\n",
    "                    refit=True,\n",
    "                    optimizer_kwargs={'base_estimator': 'GP'},\n",
    "                    random_state=RANDOM_SEED,\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "democratic-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Searching for the next optimal point.\n",
      "Iteration No: 1 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.0094\n",
      "Function value obtained: 0.5059\n",
      "Current minimum: 0.5059\n",
      "Iteration No: 2 started. Searching for the next optimal point.\n",
      "Iteration No: 2 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.6345\n",
      "Function value obtained: 0.4056\n",
      "Current minimum: 0.4056\n",
      "Iteration No: 3 started. Searching for the next optimal point.\n",
      "Iteration No: 3 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.5644\n",
      "Function value obtained: 0.3991\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 4 started. Searching for the next optimal point.\n",
      "Iteration No: 4 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4395\n",
      "Function value obtained: 0.4035\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 5 started. Searching for the next optimal point.\n",
      "Iteration No: 5 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.4323\n",
      "Function value obtained: 0.3999\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.1366\n",
      "Function value obtained: 0.5426\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.0988\n",
      "Function value obtained: 0.4349\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.5679\n",
      "Function value obtained: 0.4197\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.1757\n",
      "Function value obtained: 0.4025\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9192\n",
      "Function value obtained: 0.6489\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7561\n",
      "Function value obtained: 0.4022\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.0909\n",
      "Function value obtained: 0.4544\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.6448\n",
      "Function value obtained: 0.4560\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.7022\n",
      "Function value obtained: 0.4019\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.0854\n",
      "Function value obtained: 0.4489\n",
      "Current minimum: 0.3991\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.7812\n",
      "Function value obtained: 0.3964\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4623\n",
      "Function value obtained: 0.4037\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.5685\n",
      "Function value obtained: 0.3991\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1517\n",
      "Function value obtained: 0.4038\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.2358\n",
      "Function value obtained: 0.4032\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.3099\n",
      "Function value obtained: 0.4058\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.8912\n",
      "Function value obtained: 0.3966\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.0427\n",
      "Function value obtained: 0.4014\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.6897\n",
      "Function value obtained: 0.3966\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.9614\n",
      "Function value obtained: 0.3967\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3880\n",
      "Function value obtained: 0.4035\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3468\n",
      "Function value obtained: 0.4016\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.8709\n",
      "Function value obtained: 0.4031\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.2642\n",
      "Function value obtained: 0.4058\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.9045\n",
      "Function value obtained: 0.3964\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 13.7007\n",
      "Function value obtained: 0.3967\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.2607\n",
      "Function value obtained: 0.4000\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5051\n",
      "Function value obtained: 0.4005\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2423\n",
      "Function value obtained: 0.4023\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.2093\n",
      "Function value obtained: 0.4000\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.8455\n",
      "Function value obtained: 0.4031\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.7570\n",
      "Function value obtained: 0.4004\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 13.9156\n",
      "Function value obtained: 0.4017\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6009\n",
      "Function value obtained: 0.4020\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.4616\n",
      "Function value obtained: 0.3966\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.6801\n",
      "Function value obtained: 0.3967\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.6782\n",
      "Function value obtained: 0.4027\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.9899\n",
      "Function value obtained: 0.3999\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.7360\n",
      "Function value obtained: 0.4028\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.1121\n",
      "Function value obtained: 0.3981\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 18.3519\n",
      "Function value obtained: 0.4006\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.9361\n",
      "Function value obtained: 0.4010\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.9228\n",
      "Function value obtained: 0.3964\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.1376\n",
      "Function value obtained: 0.3964\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.6320\n",
      "Function value obtained: 0.3964\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.2432\n",
      "Function value obtained: 0.4002\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.7436\n",
      "Function value obtained: 0.4003\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.9115\n",
      "Function value obtained: 0.3978\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.3901\n",
      "Function value obtained: 0.4018\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 14.1858\n",
      "Function value obtained: 0.3966\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.3947\n",
      "Function value obtained: 0.4010\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.0099\n",
      "Function value obtained: 0.4002\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.0833\n",
      "Function value obtained: 0.3998\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.5508\n",
      "Function value obtained: 0.4000\n",
      "Current minimum: 0.3964\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "RandomForest - candidates checked: 59, best CV score: -0.396 ± 0.035\n",
      "Best parameters:\n",
      "OrderedDict([('bootstrap', True),\n",
      "             ('max_depth', 22),\n",
      "             ('max_features', 'sqrt'),\n",
      "             ('min_samples_leaf', 1),\n",
      "             ('min_samples_split', 2),\n",
      "             ('n_estimators', 1001)])\n"
     ]
    }
   ],
   "source": [
    "optimizer, best_params = report_perf(opt, X_train_lof_rs, y_train_lof,'RandomForest', \n",
    "                          callbacks=[VerboseCallback(100), \n",
    "                                     DeadlineStopper(60*10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "surrounded-camera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48410370684888615\n"
     ]
    }
   ],
   "source": [
    "best_reg_rf = RandomForestRegressor(**best_params,\n",
    "                       random_state=RANDOM_SEED)\n",
    "\n",
    "best_reg_rf.fit(X_train_lof_rs, y_train_lof)\n",
    "best_pred_rf = best_reg.predict(X_test_lof_rs)\n",
    "\n",
    "print(np.mean(np.square(best_pred_rf - y_test_lof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-brooks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hindu-technical",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "black-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5687022900763359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mse_by_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.817969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.082316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.216085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.328223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.960480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.210739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  mse_by_target\n",
       "3  0.000000       3.817969\n",
       "4  0.000000       2.082316\n",
       "5  0.794643       0.216085\n",
       "6  0.504854       0.328223\n",
       "7  0.250000       0.960480\n",
       "8  0.000000       3.210739"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_rf, acc_rf = result_analysis(best_pred_rf, y_test_lof)\n",
    "\n",
    "print(acc_rf)\n",
    "df_acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-manhattan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
