{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ordered-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "# from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "# from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from scipy.stats import randint\n",
    "\n",
    "from scipy.stats import expon, reciprocal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-patent",
   "metadata": {},
   "source": [
    "# Model Tuning: Preprocess to Hyperparameter Tuning\n",
    "Linear Regression & SVM Regressor\n",
    "\n",
    "<br>\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "<br>\n",
    "\n",
    "### Result\n",
    "- Best Cross Validation (StratifiedKFold, n_splits=5) MSE\n",
    "    - 0.420\n",
    "- Test MSE\n",
    "    - 0.471\n",
    "\n",
    "<br>\n",
    "\n",
    "### Setting\n",
    "- Local Outlier Factor\n",
    "    - `n_neighbors` = 23\n",
    "    - applied to stratified train set (StandardScaler)  \n",
    "- Pipeline\n",
    "```python\n",
    "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=32, random_state=2021, svd_solver='auto', tol=0.0, whiten=False),\n",
    " 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), n_features_to_select=65, step=1, verbose=0),\n",
    " 'poly': PolynomialFeatures(degree=2, include_bias=False, interaction_only=True,\n",
    "                   order='C'), 'poly__degree': 2, 'poly__include_bias': False,\n",
    " 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
    " 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Model Performance in Detail\n",
    "- accuracy (반올림한 예측값과 실제 타깃이 같은 비율)\n",
    "    - 0.603\n",
    "- mse_by_target = 각 실제 타깃별로 계산한 MSE\n",
    "\n",
    "target|accuracy|mse_by_target\n",
    "-|-|-\n",
    "3|0.000000|1.737492\n",
    "4|0.000000|2.368812\n",
    "5|0.758929|0.317865\n",
    "6|0.611650|0.286689\n",
    "7|0.312500|0.770513\n",
    "8|0.000000|2.146317\n",
    "\n",
    "<br>\n",
    "\n",
    "## SVM Regressor\n",
    "\n",
    "<br>\n",
    "\n",
    "### Result\n",
    "- Best Cross Validation (StratifiedKFold, n_splits=5) MSE\n",
    "    - 0.402\n",
    "- Test MSE\n",
    "    - 0.495\n",
    "\n",
    "<br>\n",
    "\n",
    "### Setting\n",
    "- Local Outlier Factor\n",
    "    - `n_neighbors` = 22\n",
    "    - applied to NON-stratified train set (StandardScaler)  \n",
    "- Pipeline\n",
    "\n",
    "```python\n",
    "{'scale': StandardScaler(copy=True, with_mean=True, with_std=True), \n",
    " 'regressor': SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001, kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### Model Performance in Detail\n",
    "- accuracy (반올림한 예측값과 실제 타깃이 같은 비율)\n",
    "    - 0.59\n",
    "- mse_by_target = 각 실제 타깃별로 계산한 MSE\n",
    "\n",
    "\n",
    "target|accuracy|mse_by_target\n",
    "-|-|-\n",
    "3|0.000000|4.496266\n",
    "4|0.000000|1.753694\n",
    "5|0.763158|0.193075\n",
    "6|0.621359|0.269660\n",
    "7|0.148148|0.934924\n",
    "8|0.000000|2.211116\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-party",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "artificial-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.8              0.88         0.00             2.6      0.098   \n",
       "1            7.8              0.76         0.04             2.3      0.092   \n",
       "2           11.2              0.28         0.56             1.9      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "1                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "2                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.8        5  \n",
       "1      9.8        5  \n",
       "2      9.8        6  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "red = pd.read_csv('./data/winequality-red.csv', sep=';')\n",
    "red = red.drop_duplicates(keep='last', ignore_index=True)\n",
    "red.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "nutritional-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-development",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scientific-drain",
   "metadata": {},
   "source": [
    "# Tuning LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "southeast-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pipeline\n",
    "pipe_base = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "# base parameter\n",
    "param_base = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "              }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "essential-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_grid_search_with_pipeline(Xtr, Xte, ytr, yte, pipe, params, iter_num, seed,\n",
    "                                     is_not_mute=1, stratify=True):\n",
    "    if stratify:\n",
    "        r_grid = RandomizedSearchCV(pipe, params,\n",
    "                             scoring = 'neg_mean_squared_error',\n",
    "                             cv=StratifiedKFold(n_splits=5,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=seed),\n",
    "                             verbose=is_not_mute, n_jobs=-1, n_iter=iter_num, random_state=seed)\n",
    "    else:\n",
    "        r_grid = RandomizedSearchCV(pipe, params,\n",
    "                             scoring = 'neg_mean_squared_error',\n",
    "                             cv=KFold(n_splits=5,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=seed),\n",
    "                             verbose=is_not_mute, n_jobs=-1, n_iter=iter_num, random_state=seed)\n",
    "    \n",
    "    r_grid.fit(Xtr, ytr)\n",
    "    if is_not_mute:\n",
    "        print(r_grid.best_params_)\n",
    "        print('Best CV MSE', -1 * r_grid.best_score_)\n",
    "        print('Test MSE', np.mean(np.square(r_grid.predict(Xte) - yte)))\n",
    "    return r_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "olive-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOF tuning\n",
    "def LOF_tuning(df, param_dict, pipe, pipe_param_dict, stratify = True, seed=2021):\n",
    "    \n",
    "    def split_data(df, seed, stratify=True):\n",
    "        X = df.drop('quality',axis=1)\n",
    "        y = df['quality']\n",
    "        if stratify:\n",
    "            return train_test_split(X, y,\n",
    "                                    test_size=0.2,\n",
    "                                    stratify=y,\n",
    "                                    shuffle=True,\n",
    "                                    random_state=seed)\n",
    "        else:\n",
    "            return train_test_split(X, y,\n",
    "                                    test_size=0.2,\n",
    "                                    shuffle=True,\n",
    "                                    random_state=seed)\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = split_data(df, seed=seed, stratify=stratify)\n",
    "    \n",
    "    # normalize data\n",
    "    X_scaler = param_dict['scaler']\n",
    "    X_train_std = X_scaler.fit_transform(Xtrain)\n",
    "    X_test_std = X_scaler.transform(Xtest)\n",
    "    \n",
    "    best_cv_score = 100\n",
    "    best_n_neighbors = 0\n",
    "    best_grid = ''\n",
    "    best_dataset = []\n",
    "    \n",
    "    # outlier removal using Local Outlier Factor\n",
    "    n_neighbors_list = param_dict['n_neighbors']\n",
    "    for i, nn in enumerate(n_neighbors_list):\n",
    "        lof = LocalOutlierFactor(n_neighbors=nn)\n",
    "        y_pred_std = lof.fit_predict(X_train_std)\n",
    "        outlier_idx = np.where(y_pred_std==-1)[0]\n",
    "        \n",
    "        X_train_lof, X_test_lof, y_train_lof, y_test_lof = split_data(df.drop(outlier_idx),\n",
    "                                                                     seed=seed,\n",
    "                                                                     stratify=stratify)        \n",
    "        rand_grid = random_grid_search_with_pipeline(X_train_lof,\n",
    "                                                     X_test_lof,\n",
    "                                                     y_train_lof,\n",
    "                                                     y_test_lof,\n",
    "                                                     pipe,\n",
    "                                                     pipe_param_dict,\n",
    "                                                     iter_num=1000,\n",
    "                                                     seed=seed,\n",
    "                                                     is_not_mute=0,\n",
    "                                                     stratify=stratify)\n",
    "    \n",
    "        if (-1 * rand_grid.best_score_) < best_cv_score:\n",
    "            best_cv_score = -1 * rand_grid.best_score_\n",
    "            best_grid = rand_grid\n",
    "            best_n_neighbors = nn\n",
    "            best_dataset = X_train_lof, X_test_lof, y_train_lof, y_test_lof\n",
    "            print(f'update: {best_cv_score}')\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('/', end=' ')\n",
    "        \n",
    "    return best_dataset, best_n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-portland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "twelve-office",
   "metadata": {},
   "source": [
    "### LOF Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "choice-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.44235386764106455\n",
      "/ update: 0.4397925084980251\n",
      "update: 0.43973623431059394\n",
      "/ update: 0.4395969227147248\n",
      "update: 0.43823114966631493\n",
      "/ update: 0.43736501161903985\n",
      "update: 0.4372322596052342\n",
      "update: 0.43531433888396764\n"
     ]
    }
   ],
   "source": [
    "lof_param_mms = {'scaler':MinMaxScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_mms, best_neighbor_param_mms = LOF_tuning(red, lof_param_mms,\n",
    "                                                        pipe_base, param_base,\n",
    "                                                        seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "parental-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4537990348545894\n",
      "/ update: 0.44976770994854903\n",
      "update: 0.44823105692754084\n",
      "update: 0.44534316785385136\n",
      "update: 0.44316195848503276\n",
      "update: 0.44019491939965744\n",
      "/ update: 0.43230276932920597\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_ss = {'scaler':StandardScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_ss, best_neighbor_param_ss = LOF_tuning(red, lof_param_ss,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "little-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.44349581805409233\n",
      "/ update: 0.4432501610854895\n",
      "/ update: 0.43966768788862376\n",
      "/ update: 0.43667782347747497\n",
      "update: 0.43632664159487444\n"
     ]
    }
   ],
   "source": [
    "lof_param_rs = {'scaler':RobustScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_rs, best_neighbor_param_rs = LOF_tuning(red, lof_param_rs,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "prerequisite-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# best n_neighbors = 23\n",
    "print(best_neighbor_param_ss)\n",
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = best_lof_data_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "configured-premises",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cutting-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "{'scale': MinMaxScaler(copy=True, feature_range=(0, 1)), 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "Best CV MSE 0.43230276932920597\n",
      "Test MSE 0.4777033284130501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "pipe_no_prep = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "param_no_prep = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd_no_prep = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe_no_prep, param_no_prep, iter_num=1000, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "center-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 876 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2476 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3576 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4876 tasks      | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=32, random_state=2021,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'dimension_reduce__n_components': 32, 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=65, step=1, verbose=0), 'feature_selection__n_features_to_select': 65, 'poly': PolynomialFeatures(degree=2, include_bias=False, interaction_only=True,\n",
      "                   order='C'), 'poly__degree': 2, 'poly__include_bias': False, 'poly__interaction_only': True, 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Best CV MSE 0.41978718778660085\n",
      "Test MSE 0.4709478820711314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "pipe_rfe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(LinearRegression())),\n",
    "                ('dimension_reduce', PCA()),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "param_grid_rfe = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[2],\n",
    "               'poly__interaction_only':[True, False],\n",
    "               'poly__include_bias':[True, False],\n",
    "              'feature_selection' : [RFE(LinearRegression())],\n",
    "              'feature_selection__n_features_to_select' : randint(low=10, high=70),\n",
    "              'dimension_reduce' : [PCA(random_state=RANDOM_SEED)],\n",
    "              'dimension_reduce__n_components' : randint(low=10, high=50)\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe_rfe, param_grid_rfe, iter_num=1000, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-portugal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "optical-egypt",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "centered-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_grid_model(grid_param_dict, Xtr, Xte, ytr, yte, y_scaler=None, no_prep=False):\n",
    "    \n",
    "    def pipeline_application(pipeline, dataX, datay=None, test=False):\n",
    "        result = dataX\n",
    "        if not test:\n",
    "            for pipe in pipeline:\n",
    "                try:\n",
    "                    result = pipe.fit_transform(result)\n",
    "                except:\n",
    "                    result = pipe.fit_transform(result, datay)\n",
    "            return result, pipeline\n",
    "        else:\n",
    "            for pipe in pipeline:\n",
    "                result = pipe.transform(result)\n",
    "            return result\n",
    "        \n",
    "    def make_2d_array(data):\n",
    "        return np.array(data).reshape(-1,1)\n",
    "\n",
    "    scaler = grid_param_dict['scale']\n",
    "    model = grid_param_dict['regressor']\n",
    "    \n",
    "    if y_scaler:\n",
    "        ys = y_scaler\n",
    "        ytr = ys.fit_transform(make_2d_array(ytr))\n",
    "    \n",
    "    if no_prep:\n",
    "        pipeline = [scaler]\n",
    "    else:\n",
    "        poly = grid_param_dict['poly']\n",
    "        feature_selector = grid_param_dict['feature_selection']\n",
    "        dim_reduce = grid_param_dict['dimension_reduce']\n",
    "        pipeline = [scaler, poly, feature_selector, dim_reduce]\n",
    "\n",
    "    Xtr_preprocess, pipeline = pipeline_application(pipeline, Xtr, datay=ytr)\n",
    "    Xte_preprocess = pipeline_application(pipeline, Xte, test=True)\n",
    "    \n",
    "    model.fit(Xtr_preprocess, ytr)\n",
    "    if y_scaler:\n",
    "        pred = model.predict(Xte_preprocess)\n",
    "        pred = ys.inverse_transform(model.predict(Xte_preprocess)).flatten()\n",
    "    else:\n",
    "        pred = model.predict(Xte_preprocess)\n",
    "    \n",
    "    return model, pred, np.mean(np.square(pred - yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "corresponding-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lin_reg, pred, test_mse = get_best_grid_model(r_grd.best_params_,\n",
    "                                               X_train_lof, X_test_lof, y_train_lof, y_test_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "casual-youth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4709478820711314"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-accountability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "desirable-wheel",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "binding-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_analysis(y_hat, y):\n",
    "    # 반올림한 예측값을 사용하여 accuracy 계산\n",
    "    acc = np.sum(np.round(y_hat) == np.array(y)) / len(y)\n",
    "    \n",
    "    # 반올림한 예측값과 실제 타깃이 같지 않은 인덱스\n",
    "    pred_false_index = pd.Series(np.round(y_hat) == np.array(y)) == False\n",
    "    \n",
    "    # 모델이 맞추는 데 실패한 타깃의 실제 값\n",
    "    pred_false_target = pd.Series(y).reset_index(drop=True)[pred_false_index]\n",
    "    \n",
    "    # 타깃 값(3,4,...,8) 별 갯수\n",
    "    false_target_vc = pred_false_target.value_counts()\n",
    "    real_target_vc = y.value_counts()\n",
    "    \n",
    "    # 타깃 값 별로 반올림한 예측값이 동일할 확률을 데이터프레임으로 저장\n",
    "    df_acc = pd.DataFrame(1-(false_target_vc / real_target_vc)).rename(columns={'quality':'accuracy'})\n",
    "    \n",
    "    # 각 타깃 값(3,4,...,8) 별로 각각의 MSE를 계산하여 저장\n",
    "    mask_target_by_unq = [(np.array(y)==unq_target) for unq_target in np.unique(y)]\n",
    "    mse_by_target = []\n",
    "    \n",
    "    for idx in df_acc.index.tolist():\n",
    "        mask = mask_target_by_unq[idx-3]\n",
    "        target_masked = np.array(y)[mask]\n",
    "        pred_masked = np.array(y_hat)[mask]\n",
    "        mse = np.mean(np.square(pred_masked - target_masked))\n",
    "        mse_by_target.append(mse)\n",
    "\n",
    "    df_acc['mse_by_target'] = mse_by_target\n",
    "    \n",
    "    return df_acc.sort_index(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "known-picnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6030534351145038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mse_by_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.737492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.368812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.317865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.286689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.770513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.146317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  mse_by_target\n",
       "3  0.000000       1.737492\n",
       "4  0.000000       2.368812\n",
       "5  0.758929       0.317865\n",
       "6  0.611650       0.286689\n",
       "7  0.312500       0.770513\n",
       "8  0.000000       2.146317"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc, acc = result_analysis(pred, y_test_lof)\n",
    "print(acc)\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-fantasy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "young-documentary",
   "metadata": {},
   "source": [
    "# Tuning SVMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "mounted-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pipeline\n",
    "pipe_base = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', svm.SVR())\n",
    "                ])\n",
    "\n",
    "# base parameter\n",
    "param_base = [              \n",
    "              {'regressor': [svm.SVR()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "              }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-robert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neither-giant",
   "metadata": {},
   "source": [
    "### Tuning LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adequate-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4078308482033344\n",
      "/ / update: 0.4020972780106876\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_mms = {'scaler':MinMaxScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_mms, best_neighbor_param_mms = LOF_tuning(red, lof_param_mms,\n",
    "                                                        pipe_base, param_base,\n",
    "                                                        seed=RANDOM_SEED,\n",
    "                                                       stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "worth-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4062723245332293\n",
      "/ update: 0.40103013734252463\n",
      "/ update: 0.39465283240868637\n",
      "/ "
     ]
    }
   ],
   "source": [
    "lof_param_ss = {'scaler':StandardScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_ss, best_neighbor_param_ss = LOF_tuning(red, lof_param_ss,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      seed=RANDOM_SEED,\n",
    "                                                     stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "passive-knight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update: 0.4121045755929818\n",
      "/ update: 0.41001452578243025\n",
      "/ update: 0.3990683812318899\n",
      "/ update: 0.39596387373699277\n"
     ]
    }
   ],
   "source": [
    "lof_param_rs = {'scaler':RobustScaler(),\n",
    "            'n_neighbors':range(10, 40)}\n",
    "best_lof_data_rs, best_neighbor_param_rs = LOF_tuning(red, lof_param_rs,\n",
    "                                                      pipe_base, param_base,\n",
    "                                                      seed=RANDOM_SEED,\n",
    "                                                     stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ultimate-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# best n_neighbors = 22\n",
    "print(best_neighbor_param_ss)\n",
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = best_lof_data_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "powered-grade",
   "metadata": {},
   "source": [
    "### Pipeline & Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "characteristic-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1137 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale': StandardScaler(copy=True, with_mean=True, with_std=True), 'regressor__kernel': 'rbf', 'regressor__gamma': 0.001, 'regressor__C': 100, 'regressor': SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
      "Best CV MSE 0.40163059908892784\n",
      "Test MSE 0.4949720689979241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "pipe_no_prep = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', svm.SVR())\n",
    "                ])\n",
    "\n",
    "param_grid_no_prep = [              \n",
    "              {'regressor': [svm.SVR()],\n",
    "               'regressor__kernel':['rbf', 'linear','sigmoid'],\n",
    "               'regressor__C': [0.001, 0.1, 0.1, 10, 100],\n",
    "               'regressor__gamma':['auto', 'scale', 1, 0.1, 1e-2, 1e-3],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "              }\n",
    "             ]\n",
    "\n",
    "# non-stratified data\n",
    "r_grd_no_prep = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe_no_prep, param_grid_no_prep, iter_num=1000, seed=RANDOM_SEED,\n",
    "                                stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "logical-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 369 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 620 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 971 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1422 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1972 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2622 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3372 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4222 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=19, random_state=2021,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'dimension_reduce__n_components': 19, 'feature_selection': RFE(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "                  gamma='scale', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "                  tol=0.001, verbose=False),\n",
      "    n_features_to_select=68, step=1, verbose=0), 'feature_selection__n_features_to_select': 68, 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=True,\n",
      "                   order='C'), 'poly__degree': 2, 'poly__include_bias': True, 'poly__interaction_only': True, 'regressor': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 'regressor__C': 10, 'regressor__gamma': 0.1, 'regressor__kernel': 'rbf', 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Best CV MSE 0.40403867175005387\n",
      "Test MSE 0.5090102722377168\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(svm.SVR())),\n",
    "                ('dimension_reduce', PCA()),\n",
    "                ('regressor', svm.SVR())\n",
    "                ])\n",
    "\n",
    "param_grid = [              \n",
    "              {'regressor': [svm.SVR()],\n",
    "               'regressor__kernel':['rbf', 'linear','sigmoid'],\n",
    "               'regressor__C': [0.001, 0.1, 0.1, 10, 100],\n",
    "               'regressor__gamma':['auto', 'scale', 1, 0.1, 1e-2, 1e-3],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[2],\n",
    "               'poly__interaction_only':[True, False],\n",
    "               'poly__include_bias':[True, False],\n",
    "              'feature_selection' : [RFE(svm.SVR())],\n",
    "              'feature_selection__n_features_to_select' : randint(low=10, high=70),\n",
    "              'dimension_reduce' : [PCA(random_state=RANDOM_SEED)],\n",
    "              'dimension_reduce__n_components' : randint(low=10, high=50)\n",
    "              }\n",
    "             ]\n",
    "\n",
    "# non-stratified data\n",
    "r_grd = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe, param_grid, iter_num=1000, seed=RANDOM_SEED,\n",
    "                                stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-intake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "choice-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4949720689979241\n"
     ]
    }
   ],
   "source": [
    "best_lin_reg, pred, test_mse = get_best_grid_model(r_grd_no_prep.best_params_,\n",
    "                                               X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                                  no_prep=True)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "attached-arthur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909090909090909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mse_by_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.496266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.753694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.193075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.934924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.211116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  mse_by_target\n",
       "3  0.000000       4.496266\n",
       "4  0.100000       1.753694\n",
       "5  0.763158       0.193075\n",
       "6  0.621359       0.269660\n",
       "7  0.148148       0.934924\n",
       "8  0.000000       2.211116"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc, accuracy = result_analysis(pred, y_test_lof)\n",
    "\n",
    "print(accuracy)\n",
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-council",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
