{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "difficult-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-cleaner",
   "metadata": {},
   "source": [
    "# Preprocess Test\n",
    "기본 Linear Regression 모델을 사용하여, 다양한 전처리 패키지의 적용 효과를 확인한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Summary\n",
    "전처리 프로세스를 적용하여 기본 선형회귀 모델의 테스트셋 MSE 향상\n",
    "- **(전처리 미적용)0.419 -> (전처리 적용)0.392**\n",
    "\n",
    "<br>\n",
    "\n",
    "1. LOF(Local Outlier Factor)\n",
    "    - 비지도 클러스터링 기반 아웃라이어 탐색\n",
    "    - 가장 유의미한 효과를 확인하였음\n",
    "\n",
    "2. PF (Polynomial Features)\n",
    "    - 기존 11개 설명변수를 조합하여 67개의 새로운 설명변수 생성, 비선형 패턴 파악에 도움될 것으로 기대\n",
    "    - 피쳐 셀렉션 및 차원축소 기법을 이어서 적용하면 추가적인 성능향상 기대 가능\n",
    "3. RFE (Recursive Feature Elimination)\n",
    "    - 주어진 모델로 데이터를 반복 학습하면서, 매 iteration마다 중요성 가장 낮은 설명변수를 제거\n",
    "4. 차원축소 기법 (PCA, TSNE, LDA)\n",
    "    - 대표적인 차원축소기법인 PCA만 테스트 진행\n",
    "\n",
    "> **아웃라이어 제거 -> 변수 생성 -> 피쳐 셀렉션 -> 차원축소** 적용 결과:\n",
    "\n",
    "> 전처리 미적용 테스트셋 MSE 0.419 -> 0.392 까지 기본 Linear Regression 모델의 성능 향상 확인.\n",
    "\n",
    "> Feature Selection 갯수, 축소할 차원 수 등의 파라미터를 RandomizedSearchCV(StratifiedKFold=5)로 탐색,\n",
    "\n",
    "> Best setting(pipeline parameter)은 아래와 같음.\n",
    "\n",
    "```python\n",
    "# Scaled 된 학습 데이터에 Local Outlier Factor 적용한 데이터로 학습\n",
    "\n",
    "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=22, random_state=None,\n",
    "     svd_solver='auto', tol=0.0, whiten=False),\n",
    " 'dimension_reduce__n_components': 20,\n",
    " 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "                                normalize=False),\n",
    "     n_features_to_select=43, step=1, verbose=0),\n",
    " 'feature_selection__n_features_to_select': 52,\n",
    " 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
    "                    order='C'),\n",
    " 'poly__degree': 2,\n",
    " 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
    " 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "## Conclusion\n",
    "- 하이퍼파라미터 튜닝을 연산량 적은 모델에 대하여 아래와 같이 진행\n",
    "    - (예시) Linear Regression (Basic), SVM Regressor (Kernel Trick), ...\n",
    "- Local Outlier Factor로 아웃라이어 제거한 학습 데이터셋 사용\n",
    "- `RandomizedSearchCV`를 이용한 파라미터 튜닝\n",
    "    - `LOF -> PF -> RFE -> PCA` 전처리 파이프라인의 세부 파라미터 튜닝\n",
    "    - 학습 모델 파라미터 튜닝 (학습방식이 다른 이하 4개 모델)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compressed-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "red = pd.read_csv('./data/winequality-red.csv', sep=';')\n",
    "red = red.drop_duplicates(keep='last', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "improving-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    X = df.drop('quality',axis=1)\n",
    "    y = df['quality']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=y,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=2021)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "knowing-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(red)\n",
    "\n",
    "X_scaler, y_scaler = StandardScaler(), StandardScaler()\n",
    "X_train_std = X_scaler.fit_transform(X_train)\n",
    "X_test_std = X_scaler.transform(X_test)\n",
    "y_train_std = y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "y_test_std = y_scaler.transform(np.array(y_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'volatile acidity',\n",
       " 'sulphates',\n",
       " 'citric acid',\n",
       " 'density',\n",
       " 'total sulfur dioxide']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_red = red.corr()\n",
    "top6_corr_vs_quality = np.abs(corr_red['quality']).sort_values(ascending=False)[1:7]\n",
    "top6_features = top6_corr_vs_quality.index.tolist()\n",
    "# top3_features = top6_features[:3]\n",
    "\n",
    "top6_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "irish-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_top6_features = red[top6_features + ['quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-rogers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enabling-simpson",
   "metadata": {},
   "source": [
    "# Local Outlier Factor\n",
    "- The number of neighbors considered (parameter n_neighbors) is typically set \n",
    "    - 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster\n",
    "    - 2) smaller than the maximum number of close by samples that can potentially be local outliers. \n",
    "- In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expanded-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "[  37   42   43   50   90  114  127  258  274  359  386  404  420  424\n",
      "  440  484  491  535  572  606  685  736  895  908 1071]\n"
     ]
    }
   ],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=20)\n",
    "y_pred = lof.fit_predict(X_train)\n",
    "outlier_idx = np.where(y_pred==-1)[0]\n",
    "print(len(outlier_idx))\n",
    "print(outlier_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    15\n",
       "6     6\n",
       "7     3\n",
       "4     1\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.iloc[outlier_idx]['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-bridal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elder-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "[  28   42   50   90  116  165  180  185  238  273  274  281  379  384\n",
      "  385  386  404  420  440  456  461  468  491  527  532  535  573  595\n",
      "  606  620  621  653  708  725  732  736  738  744  753  807  825  839\n",
      "  947  955  984  988 1067]\n"
     ]
    }
   ],
   "source": [
    "# scale 적용시 아웃라이어 판정 결과가 달라짐.\n",
    "lof = LocalOutlierFactor(n_neighbors=20)\n",
    "y_pred_std = lof.fit_predict(X_train_std)\n",
    "outlier_idx2 = np.where(y_pred_std==-1)[0]\n",
    "print(len(outlier_idx2))\n",
    "print(outlier_idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "right-google",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    20\n",
       "6    18\n",
       "7     8\n",
       "4     1\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.iloc[outlier_idx2]['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-northwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-green",
   "metadata": {},
   "source": [
    "## Vanilla vs. Local Outlier Factor\n",
    "Default Linear Regression Model\n",
    "- Vanilla MSE = 0.427\n",
    "- LOF MSE = 0.401\n",
    "- Scaled LOF MSE = 0.378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instrumental-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_train_mse(Xtr, Xte, ytr, yte, X_scaler=None, y_scaler=None):\n",
    "    lr = LinearRegression()\n",
    "    if X_scaler:\n",
    "        xs = X_scaler\n",
    "        Xtr = xs.fit_transform(Xtr)\n",
    "        Xte = xs.transform(Xte)\n",
    "    if y_scaler:\n",
    "        ys = y_scaler\n",
    "        ytr = ys.fit_transform(np.array(ytr).reshape(-1,1))\n",
    "    \n",
    "    # model train\n",
    "    lr.fit(Xtr, ytr)\n",
    "    \n",
    "    # return MSE\n",
    "    if not y_scaler:\n",
    "        return np.mean(np.square(lr.predict(Xte) - yte))\n",
    "    else:\n",
    "        return np.mean(np.square(ys.inverse_transform(lr.predict(Xte).reshape(-1)) - yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dimensional-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = split_data(red.drop(outlier_idx))\n",
    "X_train_lof2, X_test_lof2, y_train_lof2, y_test_lof2 = split_data(red.drop(outlier_idx2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electric-suspension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4190976461233711"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_mse(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exact-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4249937427430061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_mse(X_train_lof, X_test_lof, y_train_lof, y_test_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immune-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4249937427430065"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOF 적용 후 스케일러 적용시 성능 변화 없음\n",
    "lr_train_mse(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "            StandardScaler(), StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "disturbed-crack",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41579735690611885"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스케일러 적용 후 LOF 적용 시 소폭 성능 개선\n",
    "lr_train_mse(X_train_lof2, X_test_lof2, y_train_lof2, y_test_lof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vital-coffee",
   "metadata": {},
   "source": [
    "# Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "otherwise-wichita",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 11) (1087, 78) (1067, 78) (1049, 78)\n"
     ]
    }
   ],
   "source": [
    "pf1 = PolynomialFeatures(degree=2)\n",
    "X_train_pf_d2 = pf1.fit_transform(X_train)\n",
    "X_test_pf_d2 = pf1.transform(X_test)\n",
    "\n",
    "pf2 = PolynomialFeatures(degree=2)\n",
    "X_train_std_pf_d2 = pf2.fit_transform(X_train_std)\n",
    "X_test_std_pf_d2 = pf2.transform(X_test_std)\n",
    "\n",
    "pf3 = PolynomialFeatures(degree=2)\n",
    "X_train_lof_pf_d2 = pf3.fit_transform(X_train_lof)\n",
    "X_test_lof_pf_d2 = pf3.transform(X_test_lof)\n",
    "\n",
    "pf4 = PolynomialFeatures(degree=2)\n",
    "X_train_lof2_pf_d2 = pf4.fit_transform(X_train_lof2)\n",
    "X_test_lof2_pf_d2 = pf4.transform(X_test_lof2)\n",
    "\n",
    "print(X_train.shape, X_train_pf_d2.shape, X_train_lof_pf_d2.shape, X_train_lof2_pf_d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-adelaide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4190976461233711\n",
      "0.41909986484819195\n",
      "0.41000529727710927\n",
      "1.389261663826348\n"
     ]
    }
   ],
   "source": [
    "# Vanilla vs. Polynomial Features (degree=2)\n",
    "print(lr_train_mse(X_train, X_test, y_train, y_test))\n",
    "print(lr_train_mse(X_train_std_pf_d2, X_test_std_pf_d2, y_train, y_test))\n",
    "print(lr_train_mse(X_train_lof_pf_d2, X_test_lof_pf_d2, y_train_lof, y_test_lof))\n",
    "print(lr_train_mse(X_train_lof2_pf_d2, X_test_lof2_pf_d2, y_train_lof2, y_test_lof2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-ontario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-surprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "marked-aging",
   "metadata": {},
   "source": [
    "# RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "theoretical-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41978661636686554"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "rfe = RFE(lr)\n",
    "X_train_pf_d2_rfe = rfe.fit_transform(X_train_pf_d2, y_train)\n",
    "X_test_pf_d2_rfe = rfe.transform(X_test_pf_d2)\n",
    "\n",
    "lr_train_mse(X_train_pf_d2_rfe, X_test_pf_d2_rfe, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "precious-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10, 27, 17, 15,  1,\n",
       "       25, 35,  1,  5,  1, 11,  1,  1, 20,  3, 34, 21,  1,  1, 13,  8,  1,\n",
       "        7,  1, 23, 26,  1,  1, 16, 19, 18,  1, 37, 33,  1,  6, 12, 32,  1,\n",
       "        4, 31,  1,  1,  1,  1, 36, 39,  1, 22, 14, 28, 40,  1, 24, 29, 30,\n",
       "        1,  1,  1,  1,  1,  2,  1,  1,  1,  9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "premium-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39265701299785827"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, 25)\n",
    "X_train_pf_d2_rfe = rfe.fit_transform(X_train_pf_d2, y_train)\n",
    "X_test_pf_d2_rfe = rfe.transform(X_test_pf_d2)\n",
    "\n",
    "lr_train_mse(X_train_pf_d2_rfe, X_test_pf_d2_rfe, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "measured-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39751526748651816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, 25)\n",
    "X_train_lof_pf_d2_rfe = rfe.fit_transform(X_train_lof_pf_d2, y_train_lof)\n",
    "X_test_lof_pf_d2_rfe = rfe.transform(X_test_lof_pf_d2)\n",
    "\n",
    "lr_train_mse(X_train_lof_pf_d2_rfe, X_test_lof_pf_d2_rfe, y_train_lof, y_test_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "residential-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4496052647432139"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, 20)\n",
    "X_train_lof2_pf_d2_rfe = rfe.fit_transform(X_train_lof2_pf_d2, y_train_lof2)\n",
    "X_test_lof2_pf_d2_rfe = rfe.transform(X_test_lof2_pf_d2)\n",
    "\n",
    "lr_train_mse(X_train_lof2_pf_d2_rfe, X_test_lof2_pf_d2_rfe, y_train_lof2, y_test_lof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-admission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-atlantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "associate-transaction",
   "metadata": {},
   "source": [
    "# Dimenson Reduction\n",
    "- PCA\n",
    "    - https://data101.oopy.io/easy-understand-pca-lda\n",
    "- TSNE\n",
    "    - https://lovit.github.io/nlp/representation/2018/09/28/tsne/\n",
    "- LDA\n",
    "    - https://data101.oopy.io/easy-understand-pca-lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-merit",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "behind-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4174369001330111"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr_train_mse(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-infection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "underlying-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4047120613354118"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_train_pf_d2_pca = pca.fit_transform(X_train_pf_d2)\n",
    "X_test_pf_d2_pca = pca.transform(X_test_pf_d2)\n",
    "\n",
    "lr_train_mse(X_train_pf_d2_pca, X_test_pf_d2_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-season",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sharp-distribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41451787058889955"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=7)\n",
    "X_train_pf_d2_rfe_pca = pca.fit_transform(X_train_pf_d2_rfe)\n",
    "X_test_pf_d2_rfe_pca = pca.transform(X_test_pf_d2_rfe)\n",
    "\n",
    "lr_train_mse(X_train_pf_d2_rfe_pca, X_test_pf_d2_rfe_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-fault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "iraqi-windows",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4031626711701112"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=15)\n",
    "X_train_lof_pf_d2_rfe_pca = pca.fit_transform(X_train_lof_pf_d2_rfe)\n",
    "X_test_lof_pf_d2_rfe_pca = pca.transform(X_test_lof_pf_d2_rfe)\n",
    "\n",
    "lr_train_mse(X_train_lof_pf_d2_rfe_pca, X_test_lof_pf_d2_rfe_pca, y_train_lof, y_test_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-printing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stock-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44960526474344725"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "X_train_lof2_pf_d2_rfe_pca = pca.fit_transform(X_train_lof2_pf_d2_rfe)\n",
    "X_test_lof2_pf_d2_rfe_pca = pca.transform(X_test_lof2_pf_d2_rfe)\n",
    "\n",
    "lr_train_mse(X_train_lof2_pf_d2_rfe_pca, X_test_lof2_pf_d2_rfe_pca, y_train_lof2, y_test_lof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "finite-beads",
   "metadata": {},
   "source": [
    "# Simple GridSearch for Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "normal-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_with_pipeline(Xtr, Xte, ytr, yte, pipe, params):\n",
    "    grid = GridSearchCV(pipe, params,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv=StratifiedKFold(n_splits=5,\n",
    "                                              shuffle=True,\n",
    "                                              random_state=2021),\n",
    "                         verbose=1, n_jobs=-1)\n",
    "    grid.fit(Xtr, ytr)\n",
    "    print(grid.best_params_)\n",
    "    print('Best CV MSE', -1 * grid.best_score_)\n",
    "#     print('Mean CV MSE', -1 * grid.cv_results_['mean_test_score'])\n",
    "    print('Test MSE', np.mean(np.square(grid.predict(Xte) - yte)))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "nearby-pastor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': StandardScaler(copy=True, with_mean=True, with_std=True)}\n",
      "Best CV MSE 0.44863702716400455\n",
      "Test MSE 0.41909764612337114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "param_grid = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "              }\n",
    "             ]\n",
    "\n",
    "grd = grid_search_with_pipeline(X_train, X_test, y_train, y_test, pipe, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecological-trauma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:   17.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=39, step=1, verbose=0), 'feature_selection__n_features_to_select': 39, 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 2, 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "Best CV MSE 0.44484501456046965\n",
      "Test MSE 0.4263630438483234\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(LinearRegression())),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "param_grid = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[2],\n",
    "              'feature_selection' : [RFE(LinearRegression())],\n",
    "                'feature_selection__n_features_to_select' : range(20, 50)\n",
    "              }\n",
    "             ]\n",
    "\n",
    "grd = grid_search_with_pipeline(X_train, X_test, y_train, y_test, pipe, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-tribute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "assisted-gregory",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV\n",
    "- Best CV MSE 0.412\n",
    "- Test MSE 0.404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aerial-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_grid_search_with_pipeline(Xtr, Xte, ytr, yte, pipe, params, iter_num):\n",
    "    r_grid = RandomizedSearchCV(pipe, params,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv=StratifiedKFold(n_splits=5,\n",
    "                                              shuffle=True,\n",
    "                                              random_state=2021),\n",
    "                         verbose=1, n_jobs=-1, n_iter=iter_num)\n",
    "    r_grid.fit(Xtr, ytr)\n",
    "    print(r_grid.best_params_)\n",
    "    print('Best CV MSE', -1 * r_grid.best_score_)\n",
    "    print('Test MSE', np.mean(np.square(r_grid.predict(Xte) - yte)))\n",
    "    return r_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "color-upper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=30, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'dimension_reduce__n_components': 30, 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=38, step=1, verbose=0), 'feature_selection__n_features_to_select': 38, 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 2, 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)}\n",
      "Best CV MSE 0.44307943909701136\n",
      "Test MSE 0.4246970235102481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   18.1s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()),\n",
    "                ('poly', PolynomialFeatures()),\n",
    "                ('feature_selection', RFE(LinearRegression())),\n",
    "                ('dimension_reduce', PCA()),\n",
    "                ('regressor', LinearRegression())\n",
    "                ])\n",
    "\n",
    "param_grid = [              \n",
    "              {'regressor': [LinearRegression()],\n",
    "               'scale':[MinMaxScaler(), StandardScaler(), RobustScaler()],\n",
    "               'poly':[PolynomialFeatures()],\n",
    "               'poly__degree':[2],\n",
    "              'feature_selection' : [RFE(LinearRegression())],\n",
    "              'feature_selection__n_features_to_select' : randint(low=20, high=60),\n",
    "              'dimension_reduce' : [PCA()],\n",
    "              'dimension_reduce__n_components' : randint(low=20, high=40)\n",
    "              }\n",
    "             ]\n",
    "\n",
    "r_grd = random_grid_search_with_pipeline(X_train, X_test, y_train, y_test,\n",
    "                                pipe, param_grid, iter_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "mexican-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'dimension_reduce__n_components': 20, 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=52, step=1, verbose=0), 'feature_selection__n_features_to_select': 52, 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 2, 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Best CV MSE 0.44337678347123166\n",
      "Test MSE 0.4256334483039431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   18.1s finished\n"
     ]
    }
   ],
   "source": [
    "r_grd_lof = random_grid_search_with_pipeline(X_train_lof, X_test_lof, y_train_lof, y_test_lof,\n",
    "                                pipe, param_grid, iter_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "interracial-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=22, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False), 'dimension_reduce__n_components': 22, 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "                               normalize=False),\n",
      "    n_features_to_select=43, step=1, verbose=0), 'feature_selection__n_features_to_select': 43, 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
      "                   order='C'), 'poly__degree': 2, 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Best CV MSE 0.4413861465377984\n",
      "Test MSE 0.40729732323872686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   17.2s finished\n"
     ]
    }
   ],
   "source": [
    "r_grd_lof2 = random_grid_search_with_pipeline(X_train_lof2, X_test_lof2, y_train_lof2, y_test_lof2,\n",
    "                                pipe, param_grid, iter_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solar-roommate",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "Model performance(MSE) using best model from RandomizedSearchCV\n",
    "- 원본 데이터\n",
    "    - MSE -> 0.404\n",
    "- LocalOutlierFactor 데이터 (non-scaled 데이터에 적용)\n",
    "    - MSE -> 0.393\n",
    "- LocalOutlierFactor 데이터 (scaled 데이터에 적용)\n",
    "    - MSE -> 0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "english-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_grid_model(grid_param_dict, Xtr, Xte, ytr, yte):\n",
    "    \n",
    "    def pipeline_application(pipeline, dataX, datay=None, test=False):\n",
    "        result = dataX\n",
    "        if not test:\n",
    "            for pipe in pipeline:\n",
    "                try:\n",
    "                    result = pipe.fit_transform(result)\n",
    "                except:\n",
    "                    result = pipe.fit_transform(result, datay)\n",
    "            return result, pipeline\n",
    "        else:\n",
    "            for pipe in pipeline:\n",
    "                result = pipe.transform(result)\n",
    "            return result\n",
    "\n",
    "    scaler = grid_param_dict['scale']\n",
    "    poly = grid_param_dict['poly']\n",
    "    feature_selector = grid_param_dict['feature_selection']\n",
    "    dim_reduce = grid_param_dict['dimension_reduce']\n",
    "    model = grid_param_dict['regressor']\n",
    "    pipeline = [scaler, poly, feature_selector, dim_reduce]\n",
    "\n",
    "    Xtr_preprocess, pipeline = pipeline_application(pipeline, Xtr, datay=ytr)\n",
    "    Xte_preprocess = pipeline_application(pipeline, Xte, test=True)\n",
    "    \n",
    "    model.fit(Xtr_preprocess, ytr)\n",
    "    \n",
    "    return model, np.mean(np.square(model.predict(Xte_preprocess) - yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "divided-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       " 0.4262724695720125)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_grid_model(r_grd.best_params_, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "willing-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       " 0.392158043032267)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_grid_model(r_grd_lof.best_params_,\n",
    "                    X_train_lof, X_test_lof, y_train_lof, y_test_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "agricultural-intro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension_reduce': PCA(copy=True, iterated_power='auto', n_components=22, random_state=None,\n",
       "     svd_solver='auto', tol=0.0, whiten=False),\n",
       " 'dimension_reduce__n_components': 20,\n",
       " 'feature_selection': RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                normalize=False),\n",
       "     n_features_to_select=43, step=1, verbose=0),\n",
       " 'feature_selection__n_features_to_select': 52,\n",
       " 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'poly__degree': 2,\n",
       " 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       " 'scale': MinMaxScaler(copy=True, feature_range=(0, 1))}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_grd_lof.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "alleged-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       " 0.4072949307415827)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_grid_model(r_grd_lof2.best_params_,\n",
    "                    X_train_lof2, X_test_lof2, y_train_lof2, y_test_lof2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-looking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "nutritional-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 0.4028665761899813)\n",
      "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 0.3921580262048367)\n",
      "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 0.40730241230916975)\n"
     ]
    }
   ],
   "source": [
    "print(get_best_grid_model(r_grd_lof2.best_params_, X_train, X_test, y_train, y_test))\n",
    "print(get_best_grid_model(r_grd_lof2.best_params_,\n",
    "                    X_train_lof, X_test_lof, y_train_lof, y_test_lof))\n",
    "print(get_best_grid_model(r_grd_lof2.best_params_,\n",
    "                    X_train_lof2, X_test_lof2, y_train_lof2, y_test_lof2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
